# 🚢 タイタニック号生存者予測モデル（スタッキングによる汎化性能の向上）

## 概要 (Overview)

本リポジトリは、KaggleのTitanicデータセットを用いた二値分類プロジェクトの最終成果物です。単一モデルの限界を超えるため、複数の最新アルゴリズムを組み合わせた**高度なアンサンブル学習手法（スタッキング）**を適用しました。

---

## 🚀 プロジェクト・ハイライト

| 項目 | 詳細 |
| :--- | :--- |
| **最終成果** | Kaggle LBスコア **0.78468** 達成 |
| **採用手法** | **スタッキング** (ベースモデル: XGBoost, RandomForest, LightGBM / メタモデル: ロジスティック回帰) |
| **コード** | `TitanicML.ipynb` |

### 💡 最大のインサイト（分析の核心）

> **「XGBoostとRandomForestの出力を統合したスタッキング手法」**の採用により、単一モデルでは達成が困難だった**汎化性能の向上（LBスコア +0.5%）**を実現しました。特に、モデルの貢献度を定量的に分析し、データセットに最適なモデルの組み合わせを論理的に決定する重要性を実証しています。

---

## 🛠️ 主要な分析・技術的判断

### 1. 欠損値分析と傾向スコアの活用

* **論理的仮説**: `Age`の欠損はランダムではない（MAR）という仮説に基づき、統計検定を実施。
* **アクション**: 検定結果に基づき、「`Age`が欠損しているかどうか」を示す**バイナリフラグ**を**欠損の傾向スコア**として特徴量に追加し、欠損データが持つメタ情報をモデルに学習させた。

### 2. モデリングとロバスト性への考察

* **モデル選択**: 過学習に強いRandomForestと高性能なXGBoostの利点を統合するため、**スタッキング**を採用。
* **課題**: CVスコアとLBスコアの乖離を確認したことから、モデルの**過学習（ロバスト性不足）**を特定。

---

## ✨ 今後の改善点と展望

過学習の課題を解決し、モデルの安定性をさらに高めるため、以下の改善を計画しています。

* **正則化の強化**: $\lambda$や$\alpha$などの正則化パラメータの積極的なチューニング。
* **多様なアンサンブル**: ベースモデルに**ニューラルネットワーク（Keras/TensorFlow）**など異なるメカニズムを持つモデルを追加。
